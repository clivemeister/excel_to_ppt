{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-26 09:45:01,480 Starting run for 2017-12...\n",
      "2018-01-26 09:45:01,518 Importing excel file Insights.xlsx\n",
      "2018-01-26 09:45:04,946 Creating presentation for December\n",
      "2018-01-26 09:45:04,948 Modifying text in slide 0\n",
      "2018-01-26 09:45:04,954 3rd slide: large wordcloud for this month, and top 3 keywords\n",
      "2018-01-26 09:45:05,051 Top keyword/counts for month 12 : [('onesphere', 10), ('simplivity', 9), ('aruba', 8), ('iot', 7), ('pointnext', 7)]\n",
      "2018-01-26 09:45:05,882 Modifying text and adding wordcloud in slide 2\n",
      "2018-01-26 09:45:05,937 4th slide: three wordclouds for most recent 3 months\n",
      "2018-01-26 09:45:06,011 Top keyword/counts for month 11 : [('aruba', 14), ('iot', 13), ('synergy', 12), ('simplivity', 8), ('hybrid', 5)]\n",
      "2018-01-26 09:45:06,858 Top keyword/counts for month 10 : [('synergy', 16), ('aruba', 16), ('simplivity', 16), ('iot', 12), ('pointnext', 9)]\n",
      "2018-01-26 09:45:07,714 Adding three wordclouds in slide 3\n",
      "2018-01-26 09:45:07,737 5th slide: top keywords for this month\n",
      "2018-01-26 09:45:07,742 Useful rows in months 2,1,0 are 59, 40, 34\n",
      "2018-01-26 09:45:07,911 Kwd0 is onesphere, data [0.0, 0.050000000000000003, 0.29411764705882354]\n",
      "2018-01-26 09:45:08,091 Kwd1 is simplivity, data [0.2711864406779661, 0.20000000000000001, 0.26470588235294118]\n",
      "2018-01-26 09:45:08,225 Kwd0 is aruba, data [0.2711864406779661, 0.34999999999999998, 0.23529411764705882]\n",
      "2018-01-26 09:45:08,582 Adding line graphs, donuts and customers to the Top 3 Customer Interests slide (5th slide)\n",
      "2018-01-26 09:45:08,666 9th slide: industries and how they broke down across the centres\n",
      "2018-01-26 09:45:09,188 Top keyword/counts for China: []\n",
      "2018-01-26 09:45:09,354 Top keyword/counts for CME: [('pointnext', 4), ('aruba', 4), ('iot', 3), ('simplivity', 3)]\n",
      "2018-01-26 09:45:09,525 Top keyword/counts for Energy: [('iot', 4), ('simplivity', 2), ('analytics', 2), ('pathfinder', 2)]\n",
      "2018-01-26 09:45:09,714 Top keyword/counts for Fin Svcs: [('synergy', 8), ('aruba', 6), ('pointnext', 5), ('analytics', 5)]\n",
      "2018-01-26 09:45:09,899 Top keyword/counts for Health & LS: [('pathfinder', 3), ('synergy', 2), ('iot', 2), ('pointnext', 1)]\n",
      "2018-01-26 09:45:10,115 Top keyword/counts for Japan: [('pointnext', 1)]\n",
      "2018-01-26 09:45:10,380 Top keyword/counts for Mfg: [('synergy', 8), ('aruba', 8), ('iot', 6), ('simplivity', 6)]\n",
      "2018-01-26 09:45:10,610 Top keyword/counts for Other: [('aruba', 10), ('simplivity', 8), ('synergy', 6), ('nimble', 5)]\n",
      "2018-01-26 09:45:10,798 Top keyword/counts for RCG: [('aruba', 2), ('sap', 2), ('clearpass', 1), ('hybrid', 1)]\n",
      "2018-01-26 09:45:11,005 Top keyword/counts for Public Sector: [('simplivity', 7), ('iot', 6), ('aruba', 4), ('clearpass', 3)]\n",
      "2018-01-26 09:45:11,186 Top keyword/counts for Travel & Trans: [('iot', 4), ('synergy', 3), ('hybrid', 3), ('onesphere', 3)]\n",
      "2018-01-26 09:45:11,191 Adding main donut to Industry Insights slide (9th slide)\n",
      "2018-01-26 09:45:11,198 Adding donuts for top industries in each centre (9th slide)\n",
      "2018-01-26 09:45:11,200 Writing Fin Svcs as industry 0\n",
      "2018-01-26 09:45:11,227 Writing Mfg as industry 1\n",
      "2018-01-26 09:45:11,258 Writing Public Sector as industry 2\n",
      "2018-01-26 09:45:11,288 Writing CME as industry 3\n",
      "2018-01-26 09:45:11,322 Writing Health & LS as industry 4\n",
      "2018-01-26 09:45:11,361 10th slide: top partner keywords and partner attendance broken out by centre\n",
      "2018-01-26 09:45:11,453 Centres being looked at: ['PA', 'LON1', 'SNG', 'NY1', 'H']\n",
      "2018-01-26 09:45:11,454 Volume by centre - partner: [8, 4, 0, 4, 2]\n",
      "2018-01-26 09:45:11,456 Volume by centre - SI: [3, 2, 2, 0, 0]\n",
      "2018-01-26 09:45:11,458 Volume by centre - attended: [26, 13, 12, 10, 4]\n",
      "2018-01-26 09:45:11,639 top 4 partner interests: [('synergy', 15), ('simplivity', 13), ('iot', 11), ('aruba', 11)]\n",
      "2018-01-26 09:45:11,700 11th slide: top 5 interests, top 3 industries, and their top interests, by centre, for last 6 months\n",
      "2018-01-26 09:45:11,833 Top keyword/counts in PA for Other: [('aruba', 9), ('iot', 6), ('simplivity', 5)]\n",
      "2018-01-26 09:45:11,905 Top keyword/counts in PA for Mfg: [('synergy', 12), ('simplivity', 9), ('aruba', 8)]\n",
      "2018-01-26 09:45:11,970 Top keyword/counts in PA for Fin Svcs: [('aruba', 7), ('synergy', 6), ('pathfinder', 6)]\n",
      "2018-01-26 09:45:12,022 Top keyword/counts in PA for Public Sector: [('pointnext', 3), ('analytics', 3), ('clearpass', 2)]\n",
      "2018-01-26 09:45:12,082 Top keyword/counts in PA for CME: [('iot', 4), ('simplivity', 3), ('aruba', 3)]\n",
      "2018-01-26 09:45:12,148 Top keyword/counts in PA for Health & LS: [('synergy', 4), ('pathfinder', 4), ('aruba', 4)]\n",
      "2018-01-26 09:45:12,211 Top keyword/counts in PA for RCG: [('hybrid', 3), ('aruba', 2), ('converged', 2)]\n",
      "2018-01-26 09:45:12,266 Top keyword/counts in PA for Energy: [('iot', 4), ('pathfinder', 2), ('hybrid', 1)]\n",
      "2018-01-26 09:45:12,315 Top keyword/counts in PA for Travel & Trans: [('pointnext', 1), ('edgeline', 1), ('simplivity', 1)]\n",
      "2018-01-26 09:45:12,399 Top keyword/counts in PA for Non-Customer: []\n",
      "2018-01-26 09:45:12,502 Top keyword/counts in PA for China: []\n",
      "2018-01-26 09:45:12,581 Top keyword/counts in PA for Japan: [('pointnext', 1)]\n",
      "2018-01-26 09:45:12,693 Top keyword/counts in LON1 for Other: [('synergy', 6), ('iot', 5), ('nimble', 4)]\n",
      "2018-01-26 09:45:12,753 Top keyword/counts in LON1 for Fin Svcs: [('synergy', 5), ('aruba', 3), ('hybrid', 2)]\n",
      "2018-01-26 09:45:12,808 Top keyword/counts in LON1 for Public Sector: [('aruba', 6), ('synergy', 5), ('nimble', 4)]\n",
      "2018-01-26 09:45:12,861 Top keyword/counts in LON1 for RCG: [('nimble', 2), ('synergy', 2), ('3par', 1)]\n",
      "2018-01-26 09:45:12,916 Top keyword/counts in LON1 for CME: [('simplivity', 2), ('nimble', 2), ('clearpass', 1)]\n",
      "2018-01-26 09:45:12,976 Top keyword/counts in LON1 for Mfg: [('pointnext', 1)]\n",
      "2018-01-26 09:45:13,032 Top keyword/counts in LON1 for Health & LS: [('hybrid', 2), ('analytics', 2), ('aruba', 2)]\n",
      "2018-01-26 09:45:13,137 Top keyword/counts in LON1 for Non-Customer: []\n",
      "2018-01-26 09:45:13,187 Top keyword/counts in LON1 for Energy: [('aruba', 1), ('synergy', 1)]\n",
      "2018-01-26 09:45:13,251 Top keyword/counts in LON1 for Travel & Trans: [('synergy', 2), ('oneview', 2), ('superdome', 1)]\n",
      "2018-01-26 09:45:13,387 Top keyword/counts in SNG for Other: [('simplivity', 6), ('aruba', 5), ('hybrid', 4)]\n",
      "2018-01-26 09:45:13,444 Top keyword/counts in SNG for Public Sector: [('aruba', 6), ('synergy', 5), ('simplivity', 5)]\n",
      "2018-01-26 09:45:13,510 Top keyword/counts in SNG for Fin Svcs: [('synergy', 3), ('hybrid', 2), ('analytics', 2)]\n",
      "2018-01-26 09:45:13,563 Top keyword/counts in SNG for Mfg: [('iot', 5), ('hybrid', 5), ('simplivity', 5)]\n",
      "2018-01-26 09:45:13,638 Top keyword/counts in SNG for CME: [('hybrid', 4), ('iot', 3), ('simplivity', 3)]\n",
      "2018-01-26 09:45:13,702 Top keyword/counts in SNG for Non-Customer: [('synergy', 1), ('hybrid', 1), ('simplivity', 1)]\n",
      "2018-01-26 09:45:13,803 Top keyword/counts in SNG for Energy: [('analytics', 1), ('pointnext', 1), ('simplivity', 1)]\n",
      "2018-01-26 09:45:13,881 Top keyword/counts in SNG for Travel & Trans: [('iot', 2), ('hybrid', 2), ('aruba', 2)]\n",
      "2018-01-26 09:45:13,964 Top keyword/counts in SNG for Health & LS: [('synergy', 1), ('iot', 1), ('simplivity', 1)]\n",
      "2018-01-26 09:45:14,062 Top keyword/counts in SNG for RCG: [('sap', 1)]\n",
      "2018-01-26 09:45:14,188 Top keyword/counts in NY1 for Fin Svcs: [('onesphere', 3), ('synergy', 2), ('pointnext', 2)]\n",
      "2018-01-26 09:45:14,274 Top keyword/counts in NY1 for Other: [('simplivity', 4), ('3par', 3), ('iot', 2)]\n",
      "2018-01-26 09:45:14,356 Top keyword/counts in NY1 for Health & LS: [('oneview', 1), ('niara', 1), ('nimble', 1)]\n",
      "2018-01-26 09:45:14,425 Top keyword/counts in NY1 for CME: [('pointnext', 3), ('3par', 2), ('oneview', 1)]\n",
      "2018-01-26 09:45:14,535 Top keyword/counts in NY1 for Mfg: [('synergy', 1)]\n",
      "2018-01-26 09:45:14,606 Top keyword/counts in NY1 for Public Sector: [('simplivity', 4), ('synergy', 2), ('nimble', 2)]\n",
      "2018-01-26 09:45:14,676 Top keyword/counts in NY1 for RCG: [('hybrid', 2), ('synergy', 1), ('apollo', 1)]\n",
      "2018-01-26 09:45:14,775 Top keyword/counts in NY1 for Travel & Trans: [('nimble', 3), ('3par', 2), ('onesphere', 2)]\n",
      "2018-01-26 09:45:14,886 Top keyword/counts in NY1 for Energy: []\n",
      "2018-01-26 09:45:15,025 Top keyword/counts in NY1 for Non-Customer: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-26 09:45:15,162 Top keyword/counts in H for Energy: [('simplivity', 5), ('iot', 5), ('aruba', 3)]\n",
      "2018-01-26 09:45:15,220 Top keyword/counts in H for Mfg: [('simplivity', 6), ('synergy', 4), ('nimble', 4)]\n",
      "2018-01-26 09:45:15,290 Top keyword/counts in H for Other: [('simplivity', 5), ('synergy', 4), ('sap', 3)]\n",
      "2018-01-26 09:45:15,351 Top keyword/counts in H for Public Sector: [('airwave', 3), ('clearpass', 2), ('nimble', 2)]\n",
      "2018-01-26 09:45:15,413 Top keyword/counts in H for CME: [('synergy', 2), ('moonshot', 1), ('aruba', 1)]\n",
      "2018-01-26 09:45:15,475 Top keyword/counts in H for Fin Svcs: [('simplivity', 5), ('vdi', 3), ('hybrid', 2)]\n",
      "2018-01-26 09:45:15,534 Top keyword/counts in H for Health & LS: [('synergy', 5), ('iot', 3), ('oneview', 3)]\n",
      "2018-01-26 09:45:15,596 Top keyword/counts in H for RCG: [('clearpass', 1), ('sap', 1), ('edgeline', 1)]\n",
      "2018-01-26 09:45:15,662 Top keyword/counts in H for Travel & Trans: [('synergy', 2), ('analytics', 1), ('oneview', 1)]\n",
      "2018-01-26 09:45:15,764 Top keyword/counts in H for Non-Customer: [('aruba', 1), ('nimble', 1)]\n",
      "2018-01-26 09:45:15,766 Setting the title \n",
      "2018-01-26 09:45:15,770 Setting the per-centre top 5 interests, together with per-centre top 3 industries and their interests\n",
      "2018-01-26 09:45:15,790 For centre <PA> industry <0> is <Mfg>\n",
      "2018-01-26 09:45:15,822 For centre <PA> industry <1> is <Fin Svcs>\n",
      "2018-01-26 09:45:15,850 For centre <PA> industry <2> is <Public Sector>\n",
      "2018-01-26 09:45:15,923 For centre <LON1> industry <0> is <Fin Svcs>\n",
      "2018-01-26 09:45:15,947 For centre <LON1> industry <1> is <Public Sector>\n",
      "2018-01-26 09:45:15,983 For centre <LON1> industry <2> is <RCG>\n",
      "2018-01-26 09:45:16,076 For centre <SNG> industry <0> is <Public Sector>\n",
      "2018-01-26 09:45:16,110 For centre <SNG> industry <1> is <Fin Svcs>\n",
      "2018-01-26 09:45:16,149 For centre <SNG> industry <2> is <Mfg>\n",
      "2018-01-26 09:45:16,219 For centre <NY1> industry <0> is <Fin Svcs>\n",
      "2018-01-26 09:45:16,242 For centre <NY1> industry <1> is <Health & LS>\n",
      "2018-01-26 09:45:16,273 For centre <NY1> industry <2> is <CME>\n",
      "2018-01-26 09:45:16,335 For centre <H> industry <0> is <Energy>\n",
      "2018-01-26 09:45:16,356 For centre <H> industry <1> is <Mfg>\n",
      "2018-01-26 09:45:16,378 For centre <H> industry <2> is <Public Sector>\n",
      "2018-01-26 09:45:16,403 Saving Powerpoint file for December\n",
      "2018-01-26 09:45:16,526 ...and we're done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "import calendar\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.dml import MSO_THEME_COLOR\n",
    "from pptx.util import Pt\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import re\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "console=logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter=logging.Formatter('%(asctime)s %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)\n",
    "\n",
    "yyyy,mm=2017,12\n",
    "logger.info('Starting run for %i-%i...' % (yyyy,mm))\n",
    "\n",
    "# Colour codes for HPE accent and default chart colours\n",
    "TURQUOISE = '#2AD2C9'\n",
    "PURPLE    = '#5C4767'\n",
    "ORANGE    = '#FF8D6D'\n",
    "DARK_STEEL= '#5F7A6C'\n",
    "GRAY      = '#C6C9CA'\n",
    "DARK_GRAY = '#808285'\n",
    "GREEN     = '#01A982'\n",
    "BRONZE    = '#80746E'\n",
    "SLATE     = '#425563'\n",
    "\n",
    "industry_list=[\"China\",\"CME\",\"Energy\",\"Fin Svcs\",\"Health & LS\",\n",
    "            \"Japan\", \"Mfg\",\"Other\",\"RCG\",\"Public Sector\", \"Travel & Trans\"]\n",
    "centres = [\"PA\",\"LON1\",\"SNG\",\"NY1\",\"H\"]\n",
    "\n",
    "def make_date(cell_val):\n",
    "    if type(cell_val) is datetime:\n",
    "        v=cell_val.date()\n",
    "    elif type(cell_val) is str: \n",
    "        try:\n",
    "            v= datetime.strptime(cell_val,\"%b %d, %Y\").date()\n",
    "        except ValueError:\n",
    "            v=date.fromordinal(1)\n",
    "    else:\n",
    "        v=date.fromordinal(2)\n",
    "    return v\n",
    "\n",
    "def replace_strings(series,repl_dict):\n",
    "    for k,v in repl_dict.items():\n",
    "        series.str.replace(k,v)\n",
    "    return(series)\n",
    "\n",
    "def count_strings(list_of_strings,s_to_find):\n",
    "    \"\"\"Count how many times the strings in sequence s occur in the strings in list_of_strings \n",
    "       Return a Counter with the number of times each i in s occurs in one of the strings in list_of_strings\n",
    "    \"\"\"\n",
    "    if s_to_find is str:\n",
    "        count_list=sum(list_of_strings.str.find(str)>0)\n",
    "    else:\n",
    "        count_list=Counter()\n",
    "        for i in s_to_find:\n",
    "            count_list[i]=sum(list_of_strings.str.find(i)>0)\n",
    "    return count_list\n",
    "        \n",
    "def sum_of_dicts(d1,d2):\n",
    "    dd_sum={}\n",
    "    for k in set(d1.keys()).union(d2.keys()):\n",
    "        dd_sum[k]=0\n",
    "        if k in d1:\n",
    "            dd_sum[k]+=d1[k]\n",
    "        if k in d2:\n",
    "            dd_sum[k]+=d2[k]\n",
    "        if (dd_sum[k]==0): del dd_sum[k]\n",
    "    return(dd_sum)\n",
    "\n",
    "def keyword_counts_in_series(series,keywords):\n",
    "    series = replace_strings(series.str.lower().str.replace('[\\n&,.-]',' '),\n",
    "                             replace_text\n",
    "                            )\n",
    "    return(count_strings(series,keywords))\n",
    "\n",
    "def dataframe_for_month(df, year=2017, month=1):\n",
    "    \"\"\"Yields a subset the dataframe with only those rows in the given month\n",
    "       Returns a dataframe\n",
    "    \"\"\"\n",
    "    mm=month\n",
    "    yyyy=year\n",
    "    if (mm==12): mm2,yyyy2=1,yyyy+1\n",
    "    else: mm2,yyyy2=mm+1,yyyy\n",
    "    \n",
    "    logger.debug(\"Selecting rows for %i-%i\" % (yyyy,mm))\n",
    "    month_df = df.loc[ (df.date>=date(yyyy,mm,1)) & (df.date<date(yyyy2,mm2,1)) ]\n",
    "    logger.debug(\"Found %i rows for this month\" % len(month_df.index))\n",
    "    \n",
    "    return month_df\n",
    "\n",
    "def dataframe_for_6months(df, year=2017, month=1):\n",
    "    \"\"\"Yields a subset the dataframe with those rows for last 6 months up to given month\n",
    "       Returns a dataframe\n",
    "    \"\"\"\n",
    "    mm=month\n",
    "    yyyy=year\n",
    "    # calc month after this one, to set upper limit for search\n",
    "    if (mm==12): mm_end,yyyy_end=1,yyyy+1\n",
    "    else: mm_end,yyyy_end=mm+1,yyyy\n",
    "    # calc 6 months ago, to set lower limit for search\n",
    "    if (mm<=6): mm_start,yyyy_start=mm+6,yyyy-1\n",
    "    else: mm_start,yyyy_start=mm-6,yyyy\n",
    "    \n",
    "    logger.debug(\"Selecting rows for %i-%i to %i-%i\" % (yyyy_start,mm_start,yyyy,mm))\n",
    "    month_df = df.loc[ (df.date>=date(yyyy_start,mm_start,1)) & (df.date<date(yyyy_end,mm_end,1)) ]\n",
    "    logger.debug(\"Found %i rows for this month\" % len(month_df.index))\n",
    "    \n",
    "    return month_df\n",
    "\n",
    "def keywords_in_dataframe(df):\n",
    "    \"\"\" Count each keyword in the dataframe's important columns \n",
    "        Returns a Counter collection of (keyword:count)\n",
    "    \"\"\"\n",
    "    import operator   #for sorted(), used in sorting items into OrderedDict\n",
    "     \n",
    "    logger.debug(\"Counting occurrences of keywords for this month\")\n",
    "    c_wtlma = keyword_counts_in_series(df['Want to Learn More About'],vocab)\n",
    "    c_actions=keyword_counts_in_series(df['Action Items'],vocab)\n",
    "\n",
    "    logger.debug(\"Adding together the results\")\n",
    "    counter_words_to_freq = c_wtlma + c_actions\n",
    "    \n",
    "    return counter_words_to_freq\n",
    "\n",
    "def count_rows_with_comments(df):\n",
    "    \"\"\" Count the number of rows in dataframe with a comment in either <Want to Learn More About> or <Action Items>\n",
    "        Returns the count\n",
    "    \"\"\"\n",
    "    return (df[\"Want to Learn More About\"].notnull() | df[\"Action Items\"].notnull()).sum()\n",
    "\n",
    "def counts_by_centre(dataframe):\n",
    "    centre_counts = dataframe.Ctr.value_counts()\n",
    "    counts_list = (centre_counts.PA if hasattr(centre_counts,\"PA\") else 0, \n",
    "                   centre_counts.H if hasattr(centre_counts,\"H\") else 0, \n",
    "                   centre_counts.NY1 if hasattr(centre_counts,\"NY1\") else 0, \n",
    "                   centre_counts.LON1 if hasattr(centre_counts,\"LON1\") else 0, \n",
    "                   centre_counts.SNG if hasattr(centre_counts,\"SNG\") else 0\n",
    "                   )\n",
    "    return counts_list\n",
    "\n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "\n",
    "class GroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns DIFFERENT SHADES of\n",
    "       specified colors to certain words based on the color to words mapping.\n",
    "\n",
    "       Uses wordcloud.get_single_color_func\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        from wordcloud import get_single_color_func\n",
    "        self.color_func_to_words = [\n",
    "            (get_single_color_func(color), set(words))\n",
    "            for (color, words) in color_to_words.items()]\n",
    "\n",
    "        self.default_color_func = get_single_color_func(default_color)\n",
    "\n",
    "    def get_color_func(self, word):\n",
    "        \"\"\"Returns a single_color_func associated with the word\"\"\"\n",
    "        try:\n",
    "            color_func = next(\n",
    "                color_func for (color_func, words) in self.color_func_to_words\n",
    "                if word in words)\n",
    "        except StopIteration:\n",
    "            color_func = self.default_color_func\n",
    "\n",
    "        return color_func\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.get_color_func(word)(word, **kwargs)\n",
    "\n",
    "def file_wordcloud_for_month(keywords_for_month, year=2017, month=8):\n",
    "    ##Build a wordcloud, using the wordcloud code from Andreas Mueller\n",
    "    # (to install, run \"pip install wordcloud\"\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    \n",
    "    font_path = os.path.join(\"C:\",os.sep,\"Windows\",os.sep,\"Fonts\",os.sep,'arial.ttf')\n",
    "    logger.debug(\"Generating the wordcloud\")\n",
    "    wc_for_month = WordCloud(font_path=font_path,\n",
    "                             width=2500,height=500,\n",
    "                             prefer_horizontal=1.0,\n",
    "                             relative_scaling=0.7,\n",
    "                             max_font_size=196,\n",
    "                             background_color=\"white\",\n",
    "                             random_state=1\n",
    "                             ).generate_from_frequencies(keywords_for_month)\n",
    "    \n",
    "    # Create a color function with multiple tones\n",
    "    color_to_words = {\n",
    "    TURQUOISE:[\"superdome\",\"blades\",\"gen10\",\"sgi\", \"composable\", \"synergy\",\"moonshot\",\n",
    "               \"converged\",\"hyperconverged\",\"cloudline\",\"cloudsystem\",\"simplivity\",\n",
    "               \"easyconnect\",\"sap\",\"apollo\"],\n",
    "    PURPLE:[\"greenlake\",\"hpefs\",\"flex_capacity\",\"saas\"],\n",
    "    ORANGE:[\"networking\", \"wireless\", \"aruba\", \"arista\", \"clearpass\", \"naas\", \"skype\", \n",
    "            \"meridian\",\"airwave\",\"niara\"],\n",
    "    GREEN:[\"helion\", \"azurestack\",\"hybrid\",\"docker\",\"vdi\",\n",
    "                \"new_stack\",\"cloudcruiser\",\"onesphere\",\"office365\"],\n",
    "    GRAY: [\"3par\",\"bura\",\"nimble\", \"big_data\",\"scality\",\"storeonce\",\"analytics\"],\n",
    "    DARK_GRAY: [\"openstack\",\"devops\", \"oneview\"],\n",
    "    BRONZE: [\"blockchain\",\"gen-z\",\"the_machine\",\"photonics\"],\n",
    "    SLATE:[\"iot\",\"edgeline\",\"smart_city\"]\n",
    "    }\n",
    "\n",
    "    # Words that are not in any of the color_to_words values\n",
    "    # will be colored with a grey single color function\n",
    "    default_color = 'grey'\n",
    "  \n",
    "    # Apply our color function\n",
    "    #grouped_color_func = GroupedColorFunc(color_to_words, default_color)\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "    wc_for_month.recolor(color_func=grouped_color_func)\n",
    "    \n",
    "    # Build the generated image\n",
    "    plt.imshow(wc_for_month,interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure()\n",
    "    #plt.show()\n",
    "    \n",
    "    filename = \"wordcloud-\"+calendar.month_name[month]+\".png\"\n",
    "    plt.imsave(filename,wc_for_month,format=\"png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "\n",
    "def file_graph_for_month_kwd(kwd,kwd_pos,vals,months,line_color):\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.clear()\n",
    "    ax.plot(vals,line_color,linewidth=3)\n",
    "    #ax.set_title(kwd,fontsize=48)\n",
    "    ax.set_axis_off()\n",
    "    m_minus_2_percent = \"{0:.0f}%\".format(vals[0] * 100)\n",
    "    m_this_percent    = \"{0:.0f}%\".format(vals[2] * 100)\n",
    "    ax.text(0,vals[0],calendar.month_name[months[0]]+\"\\n\"+m_minus_2_percent,fontsize=36)\n",
    "    ax.text(2,vals[2],calendar.month_name[months[2]]+\"\\n\"+m_this_percent,fontsize=36)\n",
    "    filename = \"graph-\"+str(kwd_pos)+\".png\"\n",
    "    logger.debug(\"Saving %s graph for keyword %s in file %s\" % (kwd_pos,kwd,filename))\n",
    "    fig.savefig(filename,bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def file_donut_pie_for_month(values,kwd):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('equal')\n",
    "    outside, _ = ax.pie(values,startangle=90,counterclock=False,\n",
    "                        colors=(TURQUOISE, PURPLE, ORANGE, DARK_STEEL, GRAY))\n",
    "    ax.legend((\"Palo Alto\",\"Houston\",\"NY\",\"London\",\"Singapore\"),fontsize=24,bbox_to_anchor=(0.8,1.0),frameon=False)\n",
    "    width = 0.50  #determines the thickness of donut rim\n",
    "    plt.setp( outside, width=width, edgecolor='white')\n",
    "    \n",
    "    filename = \"donut-\"+re.sub(r\"[& ]\",\"_\",str(kwd))+\".png\"\n",
    "    logger.debug(\"Saving %s donut in file %s with values %r\" % (kwd, filename, values))\n",
    "    fig.savefig(filename,bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def file_donut_pie_for_industries(industries):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('equal')\n",
    "    width = 2.0\n",
    "    outside, _ = ax.pie(industries.values,\n",
    "                        startangle=90,counterclock=False,\n",
    "                        colors=(TURQUOISE, PURPLE, ORANGE, DARK_STEEL, GRAY,DARK_GRAY),\n",
    "                        radius=5.0)\n",
    "    ax.legend(industries.index.tolist(),ncol=3,fontsize=24,loc=10,bbox_to_anchor=(0.5,-2),frameon=False)\n",
    "    plt.setp( outside, width=width, edgecolor='white')\n",
    "    \n",
    "    filename = \"donut-industries.png\"\n",
    "    logger.debug(\"Saving Industries donut in file %s with values %r\" % (filename, industries))\n",
    "    fig.savefig(filename,bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def write_customer_list(df_for_kwd,text_frame):    \n",
    "    text_frame.text = \"Customers\"\n",
    "    font=text_frame.paragraphs[0].font\n",
    "    font.size = Pt(12)\n",
    "    font.bold = True\n",
    "    font.color.theme_color = MSO_THEME_COLOR.DARK_1\n",
    "    \n",
    "    for i in (df_for_kwd)[\"Account Name\"].str.title().iteritems(): \n",
    "        new_para = text_frame.add_paragraph()\n",
    "        font=new_para.font\n",
    "        font.size = Pt(8)\n",
    "        font.color.theme_color = MSO_THEME_COLOR.DARK_2\n",
    "        new_para.text=i[1]\n",
    "    \n",
    "    return  \n",
    "\n",
    "def write_top_keywords(text_frame,titleText,kwd_counts_for_ind,rowcount):\n",
    "    \"\"\"Write a section headed by titleText, with bullets of the top 4 elements of Counter kwd_counts_for_ind plus\n",
    "       their percentage of use, where the percentage is calculated with rowcount as the denominator.\n",
    "         e.g:\n",
    "           c=Counter([(\"alpha\":5),(\"bravo\":4),(\"charlie\":3),(\"delta\":2))])\n",
    "           write_top_keywords(tf,\"My list\",c,10)  \n",
    "         yields:  \n",
    "           My list\n",
    "            - alpha - 50%\n",
    "            - bravo - 40%\n",
    "            - charlie - 30%\n",
    "    \"\"\"\n",
    "    text_frame.text = titleText\n",
    "    font=text_frame.paragraphs[0].font\n",
    "    font.size = Pt(10)\n",
    "    font.bold = True\n",
    "    font.color.theme_color = MSO_THEME_COLOR.DARK_1\n",
    "    \n",
    "    for k,v in kwd_counts_for_ind.most_common(4):\n",
    "        new_para = text_frame.add_paragraph()\n",
    "        font=new_para.font\n",
    "        font.size = Pt(8)\n",
    "        font.color.theme_color = MSO_THEME_COLOR.DARK_2\n",
    "        new_para.text=\" - \"+k+\" - \"+\"{0:.0f}%\".format(v/rowcount * 100)\n",
    "    \n",
    "    return\n",
    "\n",
    "def find_text_in_shapes(slide_shapes,searchword):\n",
    "    \"\"\"Find the given text in the list of powerpoint shapes passed in slide_shapes\n",
    "    \"\"\"\n",
    "    found_idx = -1\n",
    "    for i in range(len(slide_shapes)):\n",
    "        if (slide_shapes[i].has_text_frame):\n",
    "            text_frame = slide_shapes[i].text_frame \n",
    "            if (text_frame.text.find(searchword)>=0):\n",
    "                found_idx = i\n",
    "                break\n",
    "            \n",
    "    return found_idx\n",
    "\n",
    "def replace_text_in_shape(slide_shapes,find,use,slidename):\n",
    "    i = find_text_in_shapes(slide_shapes,find)\n",
    "    if (i>=0): \n",
    "        text_frame = slide_shapes[i].text_frame \n",
    "        text_frame.text = use\n",
    "    else:\n",
    "        logger.error(\"Could not find %s placeholder on %s\" % (find,slidename))\n",
    "    \n",
    "    return\n",
    "\n",
    "def new_run_in_slide(para,text='text',fontname='Arial',fontsize=24):\n",
    "    \"Add new run to a paragraph in a powerpoint slide\"\n",
    "    run = para.add_run()\n",
    "    run.text = text\n",
    "    font = run.font\n",
    "    font.size = Pt(fontsize)\n",
    "    font.name = fontname\n",
    "    return run\n",
    "\n",
    "replace_text={\n",
    "    \"/\": \" \",                       \"\\n\": \" \",                             \"big data\": \"big_data\",    \n",
    "    \"new stack\": \"new_stack\",       \"flexible capacity\": \"flex_capacity\",  \"flex capacity\": \"flex_capacity\",\n",
    "    \"gen z\": \"gen-z\",               \"cloud cruiser\": \"cloudcruiser\",       \"store once\": \"storeonce\",\n",
    "    \"smart city\": \"smart_city\",     \"future city\": \"smart_city\",           \"azure stack\": \"azurestack\",\n",
    "    \"intelligent edge\": \"edgeline\", \"clear pass\": \"clearpass\",             \"one view\": \"oneview\",\n",
    "    \"the machine\": \"the_machine\",   \"open stack\": \"openstack\",             \"store once\": \"storeonce\",\n",
    "    \"office 365\": \"office365\",      \"hp financial services\":\"hpefs\",       \"mobility\": \"wireless\",\n",
    "    \"hpe financial services\": \"hpefs\",     \"hpfs\": \"hpefs\",                \"integrity\": \"superdome\",\n",
    "    \"one sphere\": \"onesphere\",      \"gen 10\": \"gen10\"\n",
    "} \n",
    "\n",
    "#use this specific set of words as the vocab to look for\n",
    "vocab=[\"iot\",\"edgeline\",\"smart_city\", \"big_data\",\"sap\",\"apollo\", \"saas\", \"analytics\", \"sgi\", \n",
    "       \"networking\", \"wireless\", \"aruba\", \"arista\", \"clearpass\", \"naas\", \"skype\", \"meridian\", \n",
    "       \"airwave\",\"composable\", \"niara\", \"flex_capacity\", \"helion\", \"azurestack\",\"synergy\",\n",
    "       \"moonshot\",\"converged\",\"hyperconverged\",\"hybrid\",\"docker\",\"vdi\",\"new_stack\",\"cloudline\",\n",
    "       \"cloudsystem\",\"easyconnect\",\"openstack\",\"devops\",\"3par\",\"bura\",\"simplivity\",\"nimble\",\n",
    "       \"scality\",\"storeonce\", \"oneview\", \"office365\",\"pointnext\",\"hpefs\",\"the_machine\",\"photonics\",\n",
    "       \"blockchain\",\"pathfinder\",\"gen10\",\"gen-z\",\"cloudcruiser\",\"blades\",\"superdome\",\n",
    "       \"onesphere\",\"greenlake\"\n",
    "      ]\n",
    "\n",
    "excel_file='Insights.xlsx'\n",
    "logger.info(\"Importing excel file \"+excel_file)\n",
    "all_df = pd.read_excel(open(excel_file,'rb'),header=8)\n",
    "\n",
    "logger.debug(\"Adding structured date column\")\n",
    "all_df.insert(loc=0,column='date',value=all_df['Visit Date'].apply(make_date))\n",
    "\n",
    "## Given the month and year, calc the number of the previous few months\n",
    "if (mm==1): mm_minus_1,year_for_mm_minus_1 = 12, yyyy-1\n",
    "else: mm_minus_1, year_for_mm_minus_1 = mm-1, yyyy\n",
    "if (mm<=2): mm_minus_2,year_for_mm_minus_2 = mm+10, yyyy-1\n",
    "else: mm_minus_2, year_for_mm_minus_2 = mm-2, yyyy   \n",
    "if (mm<=6): mm_minus_6,year_for_mm_minus_6 = mm+6, yyyy-1\n",
    "else: mm_minus_6, year_for_mm_minus_6 = mm-6, yyyy      \n",
    "    \n",
    "### Now start to generate the powerpoint\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "\n",
    "# These appear to be the layouts used in the master for this slide deck\n",
    "LAYOUT_TITLE_WITH_DARK_PICTURE = 0\n",
    "LAYOUT_TITLE_SLIDE_WITH_NAME   = 1\n",
    "LAYOUT_DIVIDER                 = 2\n",
    "LAYOUT_TITLE_ONLY              = 3\n",
    "LAYOUT_TITLE_AND_SUBTITLE      = 4\n",
    "LAYOUT_BLANK                   = 5\n",
    "\n",
    "## Open up the source presentation    \n",
    "prs = Presentation('GCA_Customer_Insights_Month-Year.pptx')\n",
    "this_month = calendar.month_name[mm]\n",
    "earliest_month = calendar.month_name[mm_minus_2]\n",
    "logger.info(\"Creating presentation for %s\" % (this_month))\n",
    "\n",
    "################################################\n",
    "## Modify existing title slide with month\n",
    "################################################\n",
    "logger.info(\"Modifying text in slide 0\")\n",
    "s = prs.slides[0]\n",
    "slide_shapes = s.shapes\n",
    "text_frame = slide_shapes[0].text_frame  # should be the the title textframe\n",
    "#clear existing text, and write new text into title textframe\n",
    "text_frame.clear() \n",
    "# First para with a run of 60-point Arial font\n",
    "new_run_in_slide(text_frame.paragraphs[0],text='Customer Insights',fontname='Arial',fontsize=60)  \n",
    "# Second para with a run of 32-point font\n",
    "new_run_in_slide(text_frame.add_paragraph(),text='Learnings from '+this_month+' EBC/CEC visits',fontsize=32)    \n",
    "\n",
    "################################################\n",
    "## 3rd slide: count the keywords for this month and build the wordcloud\n",
    "################################################\n",
    "logger.info(\"3rd slide: large wordcloud for this month, and top 3 keywords\")\n",
    "df_for_month = dataframe_for_month(all_df, year=yyyy, month=mm)\n",
    "kwd_count_for_month = keywords_in_dataframe(df_for_month)\n",
    "logger.info(\"Top keyword/counts for month %i : %r\" % (mm,kwd_count_for_month.most_common(5)) )\n",
    "file_wordcloud_for_month(kwd_count_for_month,\n",
    "                         year=yyyy,month=mm)\n",
    "## Modifying main wordcloud slide by changing title and adding pic for this month's wordcloud\n",
    "logger.info(\"Modifying text and adding wordcloud in slide 2\")\n",
    "s = prs.slides[2]\n",
    "slide_shapes=s.shapes\n",
    "title_frame = slide_shapes.title.text_frame\n",
    "title_frame.clear()\n",
    "new_run_in_slide(title_frame.paragraphs[0],text=\"In \"+this_month+\" customers wanted to learn more about...\",\n",
    "       fontname=\"Arial\",fontsize=28)\n",
    "left=Inches(0.5); top=Inches(4.0)\n",
    "slide_shapes.add_picture(\"wordcloud-\"+this_month+\".png\",left,top,height=Inches(2.5))\n",
    "\n",
    "##Find where the placeholders are for the top 3 keywords update them\n",
    "top_3 = kwd_count_for_month.most_common(3)   # top 3 keywords for most recent month in list with their counts\n",
    "kwd0=top_3[0][0]\n",
    "kwd1=top_3[1][0]\n",
    "kwd2=top_3[2][0]\n",
    "logger.debug(\"Top 3 keywords for current month are %s %s %s\" % (kwd0,kwd1,kwd2))\n",
    "replace_text_in_shape(slide_shapes,find=\"topword_1\",use=kwd0,slidename=\"3rd slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"topword_2\",use=kwd1,slidename=\"3rd slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"topword_3\",use=kwd2,slidename=\"3rd slide\")\n",
    "\n",
    "################################################\n",
    "## 4th slide: count the keywords for previous two months, and build their wordclouds.\n",
    "################################################\n",
    "logger.info(\"4th slide: three wordclouds for most recent 3 months\")\n",
    "df_for_month_minus_1 = dataframe_for_month(all_df, year=year_for_mm_minus_1, month=mm_minus_1)\n",
    "kwd_count_for_m_minus_1 = keywords_in_dataframe(df_for_month_minus_1)\n",
    "logger.info(\"Top keyword/counts for month %i : %r\" % (mm_minus_1,kwd_count_for_m_minus_1.most_common(5)) )\n",
    "file_wordcloud_for_month(kwd_count_for_m_minus_1, year=year_for_mm_minus_1,month=mm_minus_1)\n",
    "\n",
    "df_for_month_minus_2 = dataframe_for_month(all_df, year=year_for_mm_minus_2, month=mm_minus_2)\n",
    "kwd_count_for_m_minus_2 = keywords_in_dataframe(df_for_month_minus_2)\n",
    "logger.info(\"Top keyword/counts for month %i : %r\" % (mm_minus_2,kwd_count_for_m_minus_2.most_common(5)) )\n",
    "file_wordcloud_for_month(kwd_count_for_m_minus_2, year=year_for_mm_minus_2,month=mm_minus_2)\n",
    "\n",
    "\n",
    "## Modifying 3-month wordcloud slide by adding pic for last 3 months' wordcloud\n",
    "logger.info(\"Adding three wordclouds in slide 3\")\n",
    "s = prs.slides[3]\n",
    "slide_shapes=s.shapes\n",
    "left=Inches(3.65)\n",
    "top=Inches(1.4)\n",
    "slide_shapes.add_picture(\"wordcloud-\"+calendar.month_name[mm_minus_2]+\".png\",left,top,height=Inches(1.5))\n",
    "top=Inches(3.25)\n",
    "slide_shapes.add_picture(\"wordcloud-\"+calendar.month_name[mm_minus_1]+\".png\",\n",
    "                         left,top,height=Inches(1.5))\n",
    "top=Inches(5.05)\n",
    "slide_shapes.add_picture(\"wordcloud-\"+this_month+\".png\",\n",
    "                         left,top,height=Inches(1.5))\n",
    "#Find where the placeholders are for the keywords whose frequency we are graphing and update them\n",
    "replace_text_in_shape(slide_shapes,find=\"Month-2\",use=calendar.month_name[mm_minus_2],slidename=\"4th slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"Month-1\",use=calendar.month_name[mm_minus_1],slidename=\"4th slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"Month-0\",use=calendar.month_name[mm],slidename=\"4th slide\")\n",
    "\n",
    "################################################\n",
    "## 5th slide: for top 3 keywords for this month graph their usage \n",
    "################################################\n",
    "logger.info(\"5th slide: top keywords for this month\")\n",
    "months=[mm_minus_2,mm_minus_1,mm]\n",
    "useful_rows_in_m_2 = count_rows_with_comments(df_for_month_minus_2)\n",
    "useful_rows_in_m_1 = count_rows_with_comments(df_for_month_minus_1)\n",
    "useful_rows_in_m = count_rows_with_comments(df_for_month)\n",
    "logger.info(\"Useful rows in months 2,1,0 are %i, %i, %i\" % (useful_rows_in_m_2,useful_rows_in_m_1,useful_rows_in_m))\n",
    "\n",
    "kwd0_c2 = kwd_count_for_m_minus_2[kwd0] if (kwd0 in kwd_count_for_m_minus_2) else 0\n",
    "kwd0_c1 = kwd_count_for_m_minus_1[kwd0] if (kwd0 in kwd_count_for_m_minus_1) else 0\n",
    "kwd0_c0 = kwd_count_for_month[kwd0]     # must have keyword as it came from this dictionary\n",
    "vals_kwd0=[kwd0_c2/useful_rows_in_m_2, kwd0_c1/useful_rows_in_m_1, kwd0_c0/useful_rows_in_m]\n",
    "file_linegraph_topic1 = file_graph_for_month_kwd(kwd0,\"1st\",vals_kwd0,months,TURQUOISE)\n",
    "logger.info(\"Kwd0 is %s, data %r\" % (kwd0,vals_kwd0))\n",
    "\n",
    "kwd1_c2 = kwd_count_for_m_minus_2[kwd1] if (kwd1 in kwd_count_for_m_minus_2) else 0\n",
    "kwd1_c1 = kwd_count_for_m_minus_1[kwd1] if (kwd1 in kwd_count_for_m_minus_1) else 0\n",
    "kwd1_c0 = kwd_count_for_month[kwd1]     # must have keyword as it came from this dictionary\n",
    "vals_kwd1=[kwd1_c2/useful_rows_in_m_2, kwd1_c1/useful_rows_in_m_1, kwd1_c0/useful_rows_in_m]\n",
    "file_linegraph_topic2 = file_graph_for_month_kwd(kwd1,\"2nd\",vals_kwd1,months,PURPLE)\n",
    "logger.info(\"Kwd1 is %s, data %r\" % (kwd1,vals_kwd1))\n",
    "\n",
    "kwd2_c2 = kwd_count_for_m_minus_2[kwd2] if (kwd2 in kwd_count_for_m_minus_2) else 0\n",
    "kwd2_c1 = kwd_count_for_m_minus_1[kwd2] if (kwd2 in kwd_count_for_m_minus_1) else 0\n",
    "kwd2_c0 = kwd_count_for_month[kwd2]     # must have keyword as it came from this dictionary\n",
    "vals_kwd2=[kwd2_c2/useful_rows_in_m_2, kwd2_c1/useful_rows_in_m_1, kwd2_c0/useful_rows_in_m]\n",
    "file_linegraph_topic3 = file_graph_for_month_kwd(kwd2,\"3rd\",vals_kwd2,months,ORANGE)\n",
    "logger.info(\"Kwd0 is %s, data %r\" % (kwd2,vals_kwd2))\n",
    "\n",
    "## Build a subset of the dataframe for last 3 months that uses each of the top 3 kwds in this month\n",
    "df_for_3months = pd.concat([df_for_month,df_for_month_minus_1,df_for_month_minus_2])\n",
    "df_for_kwd0 = df_for_3months.loc[(df_for_3months['Want to Learn More About'].str.lower().str.find(kwd0)>0) |\n",
    "                                 (df_for_3months['Action Items'].str.lower().str.find(kwd0)>0) \n",
    "                                ]\n",
    "df_for_kwd1 = df_for_3months.loc[(df_for_3months['Want to Learn More About'].str.lower().str.find(kwd1)>0) |\n",
    "                                 (df_for_3months['Action Items'].str.lower().str.find(kwd1)>0) \n",
    "                                ]\n",
    "df_for_kwd2 = df_for_3months.loc[(df_for_3months['Want to Learn More About'].str.lower().str.find(kwd2)>0) |\n",
    "                                 (df_for_3months['Action Items'].str.lower().str.find(kwd2)>0) \n",
    "                                ]\n",
    "\n",
    "## Create donut pies showing split of visits expressing interest in top 3 topics by centre over last 3 months\n",
    "kwd0_counts = counts_by_centre(df_for_kwd0)\n",
    "file_donut_topic1 = file_donut_pie_for_month(counts_by_centre(df_for_kwd0),\"1st\")\n",
    "file_donut_topic2 = file_donut_pie_for_month(counts_by_centre(df_for_kwd1),\"2nd\")\n",
    "file_donut_topic3 = file_donut_pie_for_month(counts_by_centre(df_for_kwd2),\"3rd\")\n",
    "\n",
    "## Add the line graphs and donut pies to the Top 3 Customer Interests chart\n",
    "logger.info(\"Adding line graphs, donuts and customers to the Top 3 Customer Interests slide (5th slide)\")\n",
    "s = prs.slides[4]\n",
    "slide_shapes=s.shapes\n",
    "#Update the title\n",
    "title_frame = slide_shapes.title.text_frame\n",
    "title_frame.clear()\n",
    "new_run_in_slide(title_frame.paragraphs[0],text=\"Top 3 Customer Interests: \"+earliest_month+\"-\"+this_month,\n",
    "       fontname=\"Arial\",fontsize=28)\n",
    "#Find where the placeholders are for the keywords whose frequency we are graphing and update them\n",
    "replace_text_in_shape(slide_shapes,find=\"Topic1\",use=kwd0,slidename=\"5th slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"Topic2\",use=kwd1,slidename=\"5th slide\")\n",
    "replace_text_in_shape(slide_shapes,find=\"Topic3\",use=kwd2,slidename=\"5th slide\")\n",
    "\n",
    "#Add the line graphs and the donuts for each of the topics    \n",
    "top=Inches(1.8); h=Inches(1.0); w=Inches(1.7)\n",
    "slide_shapes.add_picture(file_linegraph_topic1,Inches(0.7),top,height=h,width=w)\n",
    "slide_shapes.add_picture(file_linegraph_topic2,Inches(4.7),top,height=h,width=w)\n",
    "slide_shapes.add_picture(file_linegraph_topic3,Inches(8.8),top,height=h,width=w)\n",
    "w=Inches(2.1)\n",
    "slide_shapes.add_picture(file_donut_topic1,Inches(2.4),top,height=h,width=w)\n",
    "slide_shapes.add_picture(file_donut_topic2,Inches(6.45),top,height=h,width=w)\n",
    "slide_shapes.add_picture(file_donut_topic3,Inches(10.45),top,height=h,width=w)\n",
    "\n",
    "#Find where the placeholders are for the customer lists and update them\n",
    "df_for_kwd0_month0 = df_for_month.loc[(df_for_month['Want to Learn More About'].str.lower().str.find(kwd0)>0) |\n",
    "                                 (df_for_month['Action Items'].str.lower().str.find(kwd0)>0) \n",
    "                                ]\n",
    "df_for_kwd1_month0 = df_for_month.loc[(df_for_month['Want to Learn More About'].str.lower().str.find(kwd1)>0) |\n",
    "                                 (df_for_month['Action Items'].str.lower().str.find(kwd1)>0) \n",
    "                                ]\n",
    "df_for_kwd2_month0 = df_for_month.loc[(df_for_month['Want to Learn More About'].str.lower().str.find(kwd2)>0) |\n",
    "                                 (df_for_month['Action Items'].str.lower().str.find(kwd2)>0) \n",
    "                                ]\n",
    "i = find_text_in_shapes(slide_shapes,\"Customers1\")\n",
    "if (i>=0): \n",
    "    logger.debug(\"Writing list of %i customers for first keyword\" % (len(df_for_kwd0)))\n",
    "    write_customer_list(df_for_kwd0_month0,slide_shapes[i].text_frame)\n",
    "else:\n",
    "    logger.error(\"Could not find Customers1 placeholder\")\n",
    "    \n",
    "i = find_text_in_shapes(slide_shapes,\"Customers2\")\n",
    "if (i>=0): \n",
    "    logger.debug(\"Writing list of\",len(df_for_kwd1),\"customers for second keyword\")\n",
    "    write_customer_list(df_for_kwd1_month0,slide_shapes[i].text_frame)\n",
    "else:\n",
    "    logger.error(\"Could not find Customers2 placeholder\")\n",
    "    \n",
    "i = find_text_in_shapes(slide_shapes,\"Customers3\")\n",
    "if (i>=0): \n",
    "    logger.debug(\"Writing list of\",len(df_for_kwd2),\"customers for third keyword\")\n",
    "    write_customer_list(df_for_kwd2_month0,slide_shapes[i].text_frame)\n",
    "else:\n",
    "    logger.error(\"Could not find Customers3 placeholder\")\n",
    "\n",
    "################################################\n",
    "## 9th slide: Now generate the Industry Insights donuts and top keyword lists\n",
    "################################################\n",
    "logger.info(\"9th slide: industries and how they broke down across the centres\")\n",
    "## Generate the image for the big donut showing volume for all industries across the months\n",
    "industry_counts = df_for_3months[\"Updated Industry Sep6\"].value_counts()\n",
    "file_donut_ind_vols = file_donut_pie_for_industries(industry_counts)\n",
    "\n",
    "## Generate the individual donuts showing, for each industry, the spread across the centres\n",
    "\n",
    "\n",
    "# set up some dictionaries to hold the industry datasets for later\n",
    "df_for_ind={}; \n",
    "file_donut_for_ind={}; \n",
    "kwd_counts_for_ind={}   \n",
    "\n",
    "for ind in industry_list:\n",
    "    df_for_ind[ind] = df_for_3months[df_for_3months[\"Updated Industry Sep6\"]==ind]\n",
    "    file_donut_for_ind[ind] = file_donut_pie_for_month(counts_by_centre(df_for_ind[ind]),ind)\n",
    "    kwd_counts_for_ind[ind] = keywords_in_dataframe(df_for_ind[ind])\n",
    "    logger.info(\"Top keyword/counts for %s: %r\" % (ind,kwd_counts_for_ind[ind].most_common(4)) )\n",
    "\n",
    "## Now write out the charts and text on industry (9th) slide\n",
    "s = prs.slides[8]\n",
    "slide_shapes=s.shapes\n",
    "\n",
    "#Update the title\n",
    "title_frame = slide_shapes.title.text_frame\n",
    "title_frame.clear()\n",
    "new_run_in_slide(title_frame.paragraphs[0],text=\"Industry Insights \"+earliest_month+\"-\"+this_month,\n",
    "       fontname=\"Arial\",fontsize=28)\n",
    "\n",
    "#Add the one big donut showing volumes for each industry to the slide  \n",
    "logger.info(\"Adding main donut to Industry Insights slide (9th slide)\")\n",
    "left=Inches(1.7); top=Inches(1.9)\n",
    "slide_shapes.add_picture(file_donut_ind_vols,left,top,height=Inches(4.5),width=Inches(3.7))\n",
    "\n",
    "#Add the individual industry donuts broken down by centre to the slide  \n",
    "#Need to pick the top 5, excluding \"Other\", from the list in industry_list\n",
    "logger.info(\"Adding donuts for top industries in each centre (9th slide)\")\n",
    "left=Inches(8.3); top=(Inches(1.25),Inches(2.35),Inches(3.40),Inches(4.50),Inches(5.60))\n",
    "h=Inches(0.9); w=Inches(1.85)\n",
    "n=0 # used to count the number of industry pies we have placed (we can't use enumerate(industry_counts) as we don't always place a pie)\n",
    "for ind in industry_counts.index:\n",
    "    if   (ind!=\"Other\"):\n",
    "        logger.info(\"Writing %s as industry %i\" %(ind,n))\n",
    "        #Write the industry name as the main title for this box\n",
    "        replace_text_in_shape(slide_shapes,\"Industry-{}\".format(n),ind,\"9th slide\")\n",
    "        #Add the donut showing breakdown of centres that hosted this industry\n",
    "        slide_shapes.add_picture(file_donut_for_ind[ind], left,top[n], height=h,width=w)\n",
    "        #Now write the list of top interests for this industry\n",
    "        idx = find_text_in_shapes(slide_shapes,\"Top interests - {}\".format(n))\n",
    "        if (idx>=0): \n",
    "            text_frame = slide_shapes[idx].text_frame \n",
    "            write_top_keywords(text_frame,\"Top Interests - \"+ind,\n",
    "                               kwd_counts_for_ind[ind],\n",
    "                               count_rows_with_comments(df_for_ind[ind])\n",
    "                              )\n",
    "        else:\n",
    "            logger.error(\"Could not find <Top interests - {}> placeholder on 9th slide\".format(n))\n",
    "        n+=1\n",
    "    if (n>=5): break    # Stop after we've put 5 pictures in place\n",
    "\n",
    "################################################\n",
    "## 10th slide: Partner insights\n",
    "################################################ \n",
    "logger.info(\"10th slide: top partner keywords and partner attendance broken out by centre\")\n",
    "# rather copmlex expression to find which rows are partners who are attending as partners, or partner-led briefings for customers\n",
    "df_for_partners = df_for_3months.loc[ ( df_for_3months['Account Type'].isin([\"Channel/ Reseller\",\"Systems Integrator\"])\n",
    "                                        & (df_for_3months['Partner / Customer']!=\"Customer\")\n",
    "                                      ) | (df_for_3months['Partner / Customer']==\"Partner\")\n",
    "                                    ]\n",
    "kwd_count_for_partners = keywords_in_dataframe(df_for_partners)\n",
    "useful_rows_in_partners = count_rows_with_comments(df_for_partners)\n",
    "\n",
    "df_channel = df_for_partners[ df_for_partners['Account Type']==\"Channel/ Reseller\" ]\n",
    "df_SI = df_for_partners[ df_for_partners['Account Type']==\"Systems Integrator\" ]\n",
    "df_accompanied = df_for_partners[ df_for_partners['Partner / Customer']==\"Partner\" ]\n",
    "\n",
    "\n",
    "Channel_count=[len(df_channel[df_channel.Ctr==c]) for c in centres]\n",
    "SI_count=[len(df_SI[df_SI.Ctr==c]) for c in centres]\n",
    "Attended_count=[len(df_accompanied[df_accompanied.Ctr==c]) for c in centres]\n",
    "logger.info(\"Centres being looked at: %r\" %(centres))\n",
    "logger.info(\"Volume by centre - partner: %r\" %(Channel_count))\n",
    "logger.info(\"Volume by centre - SI: %r\" %(SI_count))\n",
    "logger.info(\"Volume by centre - attended: %r\" %(Attended_count))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5.5,2.2)\n",
    "y=(0.5,1,1.5,2,2.5)\n",
    "ax.barh(y,Channel_count, height=0.35, color=TURQUOISE,tick_label=centres)\n",
    "ax.barh(y,SI_count, height=0.35, left=Channel_count,color=PURPLE)\n",
    "new_base=[x+y for x,y in zip(Channel_count, SI_count)]\n",
    "ax.barh(y,Attended_count, height=0.35, left=new_base,color=ORANGE)\n",
    "ax.legend([\"Channel/ Reseller\",\"SI\",\"Partner attended with customer\"],loc='lower center',ncol=3,bbox_to_anchor=(0.5,-0.4))\n",
    "          \n",
    "file_hbar = \"barh-PartnerVolumes.png\"\n",
    "fig.savefig(file_hbar,bbox_inches=\"tight\")\n",
    "    \n",
    "plt.close(fig)\n",
    "    \n",
    "## Start to update the slide\n",
    "s = prs.slides[9]\n",
    "slide_shapes=s.shapes\n",
    "\n",
    "#Update the title\n",
    "title_frame = slide_shapes.title.text_frame\n",
    "title_frame.clear()\n",
    "new_run_in_slide(title_frame.paragraphs[0],text=\"Partner Insights (\"+earliest_month+\"-\"+this_month+\")\",\n",
    "       fontname=\"Arial\",fontsize=28)\n",
    "\n",
    "# Update the top 4 most common keywords, and their percentages\n",
    "logger.info(\"top 4 partner interests: %r\" % (kwd_count_for_partners.most_common(4)))\n",
    "for n,p in enumerate(kwd_count_for_partners.most_common(4)):\n",
    "    # p is (keyword: count) for each of the top 4 most common keywords\n",
    "    replace_text_in_shape(slide_shapes,\"Interest-{}\".format(n),p[0],\"10th slide\")\n",
    "    replace_text_in_shape(slide_shapes,\"Score-{}\".format(n),\"{0:.0f}%\".format(100*p[1]/useful_rows_in_partners),\"10th slide\")\n",
    "    \n",
    "# Place the horizontal bar graph\n",
    "slide_shapes.add_picture(file_hbar, Inches(0.9),Inches(4.4), height=Inches(2.2),width=Inches(5.5))\n",
    "\n",
    "################################################\n",
    "## 11th slide: Top interests and industries for last 6 months\n",
    "################################################ \n",
    "logger.info(\"11th slide: top 5 interests, top 3 industries, and their top interests, by centre, for last 6 months\")\n",
    "df_6months = dataframe_for_6months(all_df, year=yyyy, month=mm)\n",
    "\n",
    "#build a dictionary of dataframes subsetted by centre, a dictionary of keywords by centre, \n",
    "#and a dict of top 3 industries per centre and their keywords (where the key is a tuple of (centre, industry) )\n",
    "dfs_6m_ctr={}\n",
    "kwd_counts_6m_ctr={}\n",
    "industry_counts_6m = df_6months[\"Updated Industry Sep6\"].value_counts()\n",
    "kwd_counts_6m_for_top_inds={}   \n",
    "commented_rows_for_6m={}\n",
    "\n",
    "for c in centres:\n",
    "    dfs_6m_ctr[c]=df_6months[df_6months.Ctr==c]\n",
    "    kwd_counts_6m_ctr[c]=keywords_in_dataframe(dfs_6m_ctr[c])\n",
    "    industry_counts_6m[c] = (dfs_6m_ctr[c])[\"Updated Industry Sep6\"].value_counts()\n",
    "    for ind in (industry_counts_6m[c]).index:\n",
    "        this_df = dfs_6m_ctr[c][ dfs_6m_ctr[c][\"Updated Industry Sep6\"]==ind ]\n",
    "        kwd_counts_6m_for_top_inds[(c,ind)]=keywords_in_dataframe( this_df )\n",
    "        commented_rows_for_6m[(c,ind)]=count_rows_with_comments(this_df)\n",
    "        logger.info(\"Top keyword/counts in %s for %s: %r\" % (c,ind,kwd_counts_6m_for_top_inds[(c,ind)].most_common(3)) )\n",
    "\n",
    "\n",
    "## Build the slide: add the interests, industries, and per-industry interests, for each of the centres\n",
    "logger.info(\"Setting the title \")\n",
    "s = prs.slides[10]\n",
    "slide_shapes=s.shapes\n",
    "#Update the title\n",
    "title_frame = slide_shapes.title.text_frame\n",
    "title_frame.clear()\n",
    "new_run_in_slide(title_frame.paragraphs[0],text=\"Breakdown by centre (\"+calendar.month_name[mm_minus_6]+\"-\"+this_month+\")\",\n",
    "       fontname=\"Arial\",fontsize=28)\n",
    "\n",
    "#Update, by centre, the top interests, and the top industries with their top interests\n",
    "logger.info(\"Setting the per-centre top 5 interests, together with per-centre top 3 industries and their interests\")\n",
    "for c in centres:\n",
    "    \n",
    "    #First, the top interests for this centre\n",
    "    for n,p in enumerate(kwd_counts_6m_ctr[c].most_common(5)):\n",
    "        # p is (keyword: count) for each of the keywords, so p[0] is the keyword itself\n",
    "        replace_text_in_shape(slide_shapes,\"{}-interest-{}\".format(c,n),p[0],\"11th slide\")\n",
    "    \n",
    "    #Next, the top industries with their interests for this centre - industry_counts_6m[c] is already ordered highest->lowest count\n",
    "    n=0  #count how many displayed - need to do this separately from the loop count, as we ignore \"Other\" as an industry group\n",
    "    for ind in industry_counts_6m[c].index:\n",
    "        if   (ind!=\"Other\"):\n",
    "            logger.info(\"For centre <%s> industry <%i> is <%s>\" %(c,n,ind))\n",
    "            #Write the list of top interests for this industry\n",
    "            idx = find_text_in_shapes(slide_shapes,\"{}-industry-{}\".format(c,n))\n",
    "            if (idx>=0): \n",
    "                write_top_keywords(slide_shapes[idx].text_frame,\n",
    "                                   ind,\n",
    "                                   kwd_counts_6m_for_top_inds[(c,ind)],\n",
    "                                   commented_rows_for_6m[(c,ind)]\n",
    "                                  )\n",
    "            else:\n",
    "                logger.error(\"Could not find <{}-industry-{}> placeholder on 11th slide\".format(c,n))\n",
    "            n+=1   #increment the number of industries written out for this centre\n",
    "        if (n>=3): break   #exit the loop after writing in 3 industries+interests\n",
    "       \n",
    "        \n",
    "################################################\n",
    "## Close the source presentations\n",
    "################################################ \n",
    "logger.info(\"Saving Powerpoint file for \"+this_month)\n",
    "prs.save('GCA_Customer_Insights_'+this_month+'-'+str(yyyy)+'.pptx')\n",
    "## Close any open figures\n",
    "plt.close(\"all\")\n",
    "logger.info(\"...and we're done!\")\n",
    "for h in list(logger.handlers): logger.removeHandler(h)   # may be several here if we've crashed sometimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin Svcs          26\n",
      "Other             13\n",
      "Health & LS       12\n",
      "CME                7\n",
      "Mfg                6\n",
      "Public Sector      5\n",
      "RCG                3\n",
      "Travel & Trans     3\n",
      "Non-Customer       1\n",
      "Energy             1\n",
      "Name: Updated Industry Sep6, dtype: int64\n",
      "Counter({'oneview': 1, 'niara': 1, 'nimble': 1})\n"
     ]
    }
   ],
   "source": [
    "print(industry_counts_6m['NY1'])\n",
    "print(kwd_counts_6m_for_top_inds[('NY1','Health & LS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_for_partners = df_for_3months.loc[ ( df_for_3months['Account Type'].isin([\"Channel/ Reseller\",\"Systems Integrator\"])\n",
    "                                        & (df_for_3months['Partner / Customer']!=\"Customer\")\n",
    "                                      ) | (df_for_3months['Partner / Customer']==\"Partner\")\n",
    "                                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_partners = df_for_3months.loc[ ( df_for_3months['Account Type'].isin([\"Channel/ Reseller\",\"Systems Integrator\"])\n",
    "                                        & (df_for_3months['Partner / Customer']!=\"Customer\")\n",
    "                                      ) | (df_for_3months['Partner / Customer']==\"Partner\")\n",
    "                                    ]\n",
    "kwd_count_for_partners = keywords_in_dataframe(df_for_partners)\n",
    "useful_rows_in_partners = count_rows_with_comments(df_for_partners)\n",
    "\n",
    "df_channel = df_for_partners[ df_for_partners['Account Type']==\"Channel/ Reseller\" ]\n",
    "df_SI = df_for_partners[ df_for_partners['Account Type']==\"Systems Integrator\" ]\n",
    "df_accompanied = df_for_partners[ df_for_partners['Partner / Customer']==\"Partner\" ]\n",
    "\n",
    "centres = [\"PA\",\"LON1\",\"SNG\",\"NY1\",\"H\"]\n",
    "Channel_count=[len(df_channel[df_channel.Ctr==c]) for c in centres]\n",
    "SI_count=[len(df_SI[df_SI.Ctr==c]) for c in centres]\n",
    "Attended_count=[len(df_accompanied[df_accompanied.Ctr==c]) for c in centres]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "y=(1,2,3,4,5)\n",
    "ax.barh(y,Channel_count, color=TURQUOISE,tick_label=centres)\n",
    "ax.barh(y,SI_count, left=Channel_count,color=PURPLE)\n",
    "new_base=[x+y for x,y in zip(Channel_count, SI_count)]\n",
    "ax.barh(y,Attended_count, left=new_base,color=ORANGE)\n",
    "ax.legend([\"Channel/ Reseller\",\"SI\",\"Partner attended with customer\"],loc='lower center',ncol=3,bbox_to_anchor=(0.5,-0.2))\n",
    "          \n",
    "filename = \"test.png\"\n",
    "fig.savefig(filename,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-25 15:02:53,399 new warning message!!\n",
      "2018-01-25 15:02:53,399 new warning message!!\n",
      "2018-01-25 15:02:53,399 new warning message!!\n",
      "2018-01-25 15:02:53,399 new warning message!!\n",
      "2018-01-25 15:02:53,399 new warning message!!\n",
      "2018-01-25 15:02:53,411 info message\n",
      "2018-01-25 15:02:53,411 info message\n",
      "2018-01-25 15:02:53,411 info message\n",
      "2018-01-25 15:02:53,411 info message\n",
      "2018-01-25 15:02:53,411 info message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "console=logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "formatter=logging.Formatter('%(asctime)s %(message)s')\n",
    "console.setFormatter(formatter)\n",
    "logger.addHandler(console)\n",
    "\n",
    "logger.warning(\"new warning message!!\")\n",
    "logger.info(\"info message\")\n",
    "for h in list(logger.handlers): logger.removeHandler(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
